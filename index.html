
<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
  <head>
    <meta name=viewport content='width=800'>
    <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
    <style type="text/css">
      /* Color scheme stolen from Sergey Karayev */
      a {
      color: #1772d0;
      text-decoration:none;
      }
      p {
        font-size: 15px;
      }
      a:focus, a:hover {
      color: #f09228;
      text-decoration:none;
      }
      body,td,th {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px
      }
      strong {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px;
      }
      heading {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 24 px;
      }
      papertitle {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 18px;
      font-weight: 700
      }
      name {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 32px;
      }
    .fade {
       transition: opacity .2s ease-in-out;
       -moz-transition: opacity .2s ease-in-out;
       -webkit-transition: opacity .2s ease-in-out;
       }
      


    img {
        display: inline;
        margin: 0 auto;
        width: 100%;
    }
   .image-cropper {
      width: 250px;
      height: 250px;
      position: relative;
      overflow: hidden;
      border-radius: 50%;
  }
   .redText { 
    color: red; 
    }
    .blueText { 
    color: blue; 
    }

    </style>
    <link rel="icon" type="image" href="img/logo.jpg">
    <title>Gunjan </title>
    <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
    <link href='http://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
  </head>
  <body>
    <table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
      <tr>
        <td>
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tr>
              <td width="67%" valign="middle">
                <p align="center">
                  <name>Gunjan Aggarwal</name>
                  </font>
                <p align> I am a second year graduate student in the department of Computer Science at <a href="https://www.gatech.edu/." target="_blank">Georgia Institute of Technology.</a>  My interests span a broad range of sub-fields in Computer Science, including Deep Learning, Machine Learning, Computer Vision and Natural Language Processing.
                        I have worked on various projects and internships involving Computer Vision and NLP tasks.  I am currently pursuing my Graduate Research under Professor <a href="https://faculty.cc.gatech.edu/~parikh/" target="_blank">Devi Parikh</a> and <a href="https://faculty.cc.gatech.edu/~dbatra/" target="_blank">Dhruv Batra</a>  where I am working on problems related to multi-modal AI.
                  <br><br>
                        This summer of 2022, I interned with Adobe Applied Science ML team as an ML intern, working on real-time generation of temporally consistent videos for face makeup transfer.
                  <br><br>
                  Prior to pursuing my Master's I was working as a Software Development Engineer-2 at Adobe, working on Adobe's Chat Application and also exploring different Computer Vision related projects. I started working at Adobe after graduating from <a href="https://www.bits-pilani.ac.in/" target="_blank">BITS Pilani</a> where I did my major in Computer Science.
                        <br><br>
                        In my free time I like to participate in adventure sports and appreciate the unexplored beauty of nature through trekking. 
                  <br><br>
                  Email: <b>gunjan10@gatech.edu</b>
                 
                <p align=center>
<!-- <a href="mailto:gunjan10@gatech.edu" target="_blank">Email</a> &nbsp/&nbsp -->
<a href="https://www.linkedin.com/in/gunjan-aggarwal-113571bb/" target="_blank">LinkedIn</a> &nbsp/&nbsp
<a href="images/Gunjan_Gatech_resume.pdf" target="_blank">Resume</a> &nbsp/&nbsp
<a href="https://scholar.google.com/citations?user=tdRP7oEAAAAJ&hl=en" target="_blank">Google Scholar</a>

                </p>
              </td>
              <td width="33%"><img class="image-cropper" src="images/gunjanAggarwalSq.png"></td>
            </tr>
          </table>
            

           <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tr>
              <td>
                <heading style="font-size:26px">Publications</heading>
              </td>
            </tr>
            
            <tr >
            
                    <td width="30%"><img id="img-opt" src="images/zson.png" alt="project_img" width="160" style="border-style: none">
                    </td>
        
                        <td valign="top" width="70%">
                        <p><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2206.12403">
            <papertitle>ZSON: Zero-Shot Object-Goal Navigation using Multimodal Goal Embeddings</papertitle></a><br>
                        <br>
            <!-- <b> Paper accepted as a workshop paper at <a href="https://neuripscreativityworkshop.github.io/2021/" target="_blank">NeurIPS 2021.</a> </b> -->
            <b> Paper accepted at <a href="https://nips.cc/" target="_blank">NeurIPS 2022.</a> </b>
            <br>
            <!-- <a href="https://sites.google.com/view/dance2music" target="_blank">Project Page</a> -->
                        <!-- <a href="https://sites.google.com/view/dance2music" target="_blank">Project Page</a> -->
                          <p>Proposed a zero-shot approach for object-goal navigation by encoding goal images into a multi-modal, semantic embedding space.
                        <br><br>
                        Achieved 4-20% improvement for object-goal navigation task over state-of-the-art methods.
                        <br><br>
                        Showed the importance of using a self-supervised pre-trained visual encoder for zero-shot transfer.
                        </p>
                        </a> </p>
                        </td>
                    </tr>

            <tr >
            
                    <td width="30%"><img id="img-opt" src="images/dance2music.png" alt="project_img" width="160" style="border-style: none">
                    </td>
        
                        <td valign="top" width="70%">
                        <p><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2107.06252">
            <papertitle>Dance2Music: Automatic Dance-driven Music Generation</papertitle></a><br>
                        <br>
            <!-- <b> Paper accepted as a workshop paper at <a href="https://neuripscreativityworkshop.github.io/2021/" target="_blank">NeurIPS 2021.</a> </b> &nbsp &nbsp &nbsp &nbsp &nbsp<a href="https://sites.google.com/view/dance2music" target="_blank">Project Page</a> -->
            <b> Paper accepted as a workshop paper at <a href="https://neuripscreativityworkshop.github.io/2021/" target="_blank">NeurIPS 2021.</a> </b>
            <br>
            <a href="https://sites.google.com/view/dance2music" target="_blank">Project Page</a>
                        <br>
                        <!-- <a href="https://sites.google.com/view/dance2music" target="_blank">Project Page</a> -->
                          <p>Proposed an approach to generate music conditioned on dance in real-time.
                        <br><br>
                        Designed an offline approach to generate a paired dance and music dataset which was then used to train a deep neural network.
            <br><br>
            Human subjects favoured our approach more than other baselines.
                        </p>
                        </a> </p>
                        </td>
                    </tr>

            <tr >
            
                    <td width="30%"><img id="img-opt" src="images/NSG.png" alt="project_img" width="160" style="border-style: none">
                    </td>
        
                        <td valign="top" width="70%">
                        <p><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2007.02171">
            <papertitle>Neuro-Symbolic Generative Art: A Preliminary Study</papertitle></a><br>
                          <br>
                        <!-- <b> Paper accepted as a short paper at <a href="https://arxiv.org/abs/2007.02171" target="_blank">ICCC 2020.</a> </b> &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp<a href="https://sites.google.com/view/neuro-symbolic-art-gen" target="_blank">Project Page</a> -->
                        <b> Paper accepted as a short paper at <a href="https://arxiv.org/abs/2007.02171" target="_blank">ICCC 2020.</a> </b>
                        <br>
                        <a href="https://sites.google.com/view/neuro-symbolic-art-gen" target="_blank">Project Page</a>
                        <p>Proposed a new hybrid genre of art: neuro-symbolic generative art (NSG).
                        <br><br>
                        A progressive GAN was trained over the dataset collected from symbolic art approach.
                        <br><br>
                        Evaluated the creativity of NSG vs the creativity of the original symbolic data through human studies. Human subjects rated the NSG art as more creative than the symbolic art.
                        
                        </p>
                        </a> </p>
                        </td>
                    </tr>
            <tr >
              <td width="30%"><img id="img-opt" src="images/paper1.png" alt="project_img" width="160" style="border-style: none">
                  </td>
      
                    <td valign="top" width="70%">
                      <p><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2005.01499">
        <papertitle>On the Benefits of Models with Perceptually-Aligned Gradients</papertitle></a><br>
                      <br>
                  <b> Paper accepted as a workshop paper at <a href="https://trustworthyiclr20.github.io/" target="_blank">ICLR 2020.</a></b>  
                      <p>Explored the benefits of adversarial training for neural networks.
                      <br><br>
                      Adversarial training with small epsilon improved the model's performance for downstream tasks.
                      <br><br>
                      Showed improvement in performance for domain adaptation tasks, like SVHN to MNIST transfer, and for weakly supervised object localization task.
                           
                      </p>
                      </a> </p>
                    </td>
                  </tr>
            <tr >
              <td width="30%"><img id="img-opt" src="images/paper.png" alt="project_img" width="160" style="border-style: none">
                  </td>
      
                    <td valign="top" width="70%">
                      <p><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1912.05028">
        <papertitle>cFineGAN: Unsupervised multi-conditional fine-grained image generation</papertitle></a><br>
                      <br>
                      <b> Paper accepted as a workshop paper at <a href="https://neurips2019creativity.github.io/" target="_blank">NeurIPS 2019.</a></b> 
                      <p>Developed a multi-conditional image generation pipeline in an unsupervised way using a hierarchical GAN framework.
                      <br><br>
                      Given a texture and a shape image, the pipeline generates an output that preserves the shape of first and texture of second input image.      
                      <br><br>
                      Used standard and shape biased ImageNet pre-trained Resnet50 models to identify the shape and texture characteristics of inputs, respectively.
                      <br><br>
                      The work was also selected as one of the top 11 projects to be showcased live on stage in front of 15,000 people at Adobe MAX SNEAKS, 2019 - <a href="https://www.youtube.com/watch?v=JE5cUzXPMTA&ab_channel=AdobeCreativeCloud" target="_blank">Video link</a>.  
                      </p>
                       
                      </a> </p>
                    </td>
                  </tr>    
            
            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
              <tr>
                <td>
                  <heading style="font-size:26px">Projects</heading>
                </td>
              </tr>
              <tr >
                <td width="30%"><img id="img-pgp" src="images/sentiment.jpeg" alt="project_img" width="160" style="border-style: none">
                    </td>
        
                      <td valign="top" width="70%">
                        <p><b><span class="blueText"> Sentiment Analysis using Deep Learning </span></b><br>
                        

                        <p>Applied deep learning to perform sentiment analysis over different Indian languages.
                        <br><br>
                        Experimented  with  different  optimizers  such  as  Adam  and  Momentum  Optimizer,  and  also  withdifferent network architectures such as CNN and RNN.
                        <br><br>
                        Achieved 85% and 83% mean validation accuracy with CNN and RNN respectively over different languages.
                        <br><br>
                        Extended the project to contrast the impacts of product-centric and social cause marketing adver-tisements on users by analyzing their comments.
                      </p>
                      </td>
                    </tr>

              <tr>
                <td width="30%"><img id="img-pgp" src="images/knowledge_extraction.png" alt="project_img" width="160" style="border-style: none">
                    </td>
        
                      <td valign="top" width="70%">
                        <p><b><span class="blueText"> Knowldge Extraction</span></b><br>

                        <p>Analyzed UCI Student Performance dataset and classified the student grades using several models such as KNN, Decision trees and SVM.
                          <br><br>
                        Applied different pre-processing techniques over Census Income dataset, classified the income using Logistic Regression and computed the correlation between different features.
                        </p>
                    </td>
              </tr>

              <tr>
                <td width="30%"><img id="img-pgp" src="images/search_engine.jpeg" alt="project_img" width="160" style="border-style: none">
                    </td>
        
                      <td valign="top" width="70%">
                        <p><b><span class="blueText"> Textual Search Engine</span></b><br>
                        <p>Implemented sentence tokenization, normalization, building of inverted index and processing of wild-card queries for document retrieval on Reuters Corpus.
                        </p>
                    </td>
              </tr>

              <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
              <tr>
                <td>
                  <heading style="font-size:26px">Achievements</heading>
                </td>
              </tr>
              <tr >
                <td width="30%"><img id="img-pgp" src="images/image_tango_pic.png" alt="project_img" width="160" style="border-style: none">
                    </td>
        
                      <td valign="top" width="70%">
                        <p><b><span class="blueText"> Adobe MAX SNEAKS </span></b><br>
                        <p>One of the 11 presenters Adobe wide to present my work on multi-conditional image generation at Adobe MAX SNEAKS, 2019 - <a href="https://www.youtube.com/watch?v=JE5cUzXPMTA&ab_channel=AdobeCreativeCloud" target="_blank">Video link</a>. 
                      </p>
                      </td>
                    </tr>
              <tr >
                <td width="30%"><img id="img-pgp" src="images/code_jam.jpeg" alt="project_img" width="160" style="border-style: none">
                    </td>
        
                      <td valign="top" width="70%">
                        <p><b><span class="blueText"> Google Code Jam </span></b><br>
                        <p>Achieved a global rank of 27 in "Code Jam to I/O for Women" and got invited to attend Google I/O, 2018.
                        
                      </p>
                      </td>
                    </tr> 
            
              <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
              <tr>
                <td>
                  <heading style="font-size:26px">Experience</heading>
                </td>
              </tr>
              <tr >
                <td width="30%"><img id="img-pgp" src="images/adobe.png" alt="project_img" width="160" style="border-style: none">
                    </td>
        
                      <td valign="top" width="70%">
                        <p><b><span class="blueText"> ML Intern at Adobe, San Jose </span> | June 2022 - August 2022</b><br>
                        <p>Working on real-time generation of temporally consistent videos for face makeup transfer.
                      </p>
                      </td>
                    </tr> 
              <tr >
                <td width="30%"><img id="img-pgp" src="images/gatech.png" alt="project_img" width="160" style="border-style: none">
                    </td>
        
                      <td valign="top" width="70%">
                        <p><b><span class="blueText"> Graduate Research Assistant, Visual Intelligence Lab, Georgia Tech </span> | Aug 2021 - Present</b><br>
                        <p>Working under the supervision of Prof. Devi Parikh.
                        <br><br>
                        Exploring the creative applications of Deep Learning.
                      </p>
                      </td>
                    </tr>
              <tr >
                <td width="30%"><img id="img-pgp" src="images/adobe.png" alt="project_img" width="160" style="border-style: none">
                    </td>
        
                      <td valign="top" width="70%">
                        <p><b><span class="blueText"> Software Development Engineer-2 at Adobe, India </span> | July 2018-August 2021</b><br>
                        <p>Worked on the chatbot framework for Adobe Messaging platform from scratch, starting with Microsoft LUIS and Rasa, and moving on to designing in-house multi-lingual intent classifier by utilizing embedding from Google's Universal Sentence Encoder (USE) model. The chatbot is serving ~ 20,000 customers daily.
                        <br><br>
                        Applied HDBSCAN clustering algorithm on top of embeddings of low-confidence user utterances to identify new intents.
                        <br><br>
                        Worked on a PoC for designing a zero-shot pipeline for user intent identification using pre-trained BART model which alleviated the need to re-train model over each new intent.
                      </p>
                      </td>
                    </tr> 

              <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
              <tr>
                <td>
                  <heading style="font-size:26px">Education</heading>
                </td>
              </tr>
              <tr >
                <td width="30%"><img id="img-pgp" src="images/gatech.png" alt="project_img" width="160" style="border-style: none">
                    </td>
        
                      <td valign="top" width="70%">
                        <p><b><span class="blueText"> Master of Science in Computer Science </span></b><br>
                        <p> Georgia Institute of Technology, Atlanta | Specialization in Machine Learning.
                        <br><br>
                          Thesis advised by Prof. Devi Parikh.
                        <br><br>  
                        Expected Graduation: May 2023.
                      </p>
                      </td>
                    </tr>
              <tr >
                <td width="30%"><img id="img-pgp" src="images/bits.png" alt="project_img" width="160" style="border-style: none">
                    </td>
        
                      <td valign="top" width="70%">
                        <p><b><span class="blueText"> Bachelor Of Engineering (Hons.) in Computer Science.
 </span></b><br>
                        <p> BITS Pilani | Aug 2014 - July 2018.
                      </p>
                      </td>
                    </tr>

            <tr> 
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tr>
              <td>
                <br>
                <p align="right"><font size="2">
                  <a href="http://www.cs.berkeley.edu/~barron/" target="_blank">inspired from this website</a>
                  <!-- <a href="http://www.cs.berkeley.edu/~barron/"> this website</a> -->
                  </font>
                </p>
              </td>
            </tr>
          </table>
        </td>
      </tr>
    </table>
 <!-- Default Statcounter code for Personal Website
https://shrep.github.io/ -->
<script type="text/javascript">
var sc_project=11673319; 
var sc_invisible=1; 
var sc_security="327094c7"; 
</script>
<script type="text/javascript"
src="https://www.statcounter.com/counter/counter.js"
async></script>
<noscript><div class="statcounter"><a title="Web Analytics
Made Easy - StatCounter" href="http://statcounter.com/"
target="_blank"><img class="statcounter"
src="//c.statcounter.com/11673319/0/327094c7/1/" alt="Web
Analytics Made Easy - StatCounter"></a></div></noscript>
<!-- End of Statcounter Code -->
  </body>
</html>
